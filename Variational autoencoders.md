This is a modification of the [[autoencoder]] that intends to capture a distribution on the latent space of the input instead of just a vector, to do this, the encoder returns two vectors of the latent space, the mean and the standard deviation.
The error function contains the difference between the mean output and the input but also a component [[KL divergence]] between the distribution and a standard normal distribution N(0,1).
This term has the effect of forcing the network to make the latent space vector components to be more independent of each other and makes them in some cases reflect human understandable properties of the input, like in the example of images they can represent rotations, lightning, face emotions etc, and modifying one and leaving the rest the same csn have the effect of only modifiying that property keeping the rest constant. This effect can be tweaked by scaling the divergence term by a hyperparameter.